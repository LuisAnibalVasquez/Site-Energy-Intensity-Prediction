{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dff09d59",
   "metadata": {},
   "source": [
    "Modelado con el dataset completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1a84ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91877f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637a00c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nRounds = 5\n",
    "r_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee21afec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/preprocesada/Full_Data_sin_MultiC_sin_Skew.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c7dfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ce1e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Unnamed: 0','site_eui'])\n",
    "y = df['site_eui']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee447e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd80022",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7e27d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca86d5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcaFinal = PCA(n_components=10)\n",
    "X_selected = pcaFinal.fit_transform(X)\n",
    "X_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110cda90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fs = SelectKBest(score_func=f_regression, k='all')\n",
    "#X_selected = fs.fit_transform(X, y)\n",
    "#X_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40aa2bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e378b1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, \n",
    "                                                    y, \n",
    "                                                    shuffle = True, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state = r_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f55a81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e297a8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36112e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b074e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e261c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f9e98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8db1af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_bias_variance (m, X_train, y_train, X_test, y_test,  r):\n",
    "    avg_expected_loss, avg_bias,avg_var  = bias_variance_decomp(m, \n",
    "                                                                X_train, \n",
    "                                                                y_train.to_numpy(), \n",
    "                                                                X_test, \n",
    "                                                                y_test.to_numpy(), \n",
    "                                                                loss='mse', \n",
    "                                                                num_rounds=r, \n",
    "                                                                random_seed=1)\n",
    "    print('Bias Variance analisys')\n",
    "    print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "    print('Average bias: %.3f' % avg_bias)\n",
    "    print('Average variance: %.3f' % avg_var ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29aa88d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, x_test, y_test):\n",
    "    from sklearn import metrics\n",
    "    y_pred = model.predict(x_test)\n",
    "    rmse = metrics.mean_squared_error(y_test, y_pred, squared=False) # squared=False retorna RMSE / squared=True retorna MSE\n",
    "    return {'rmse': rmse}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91cd006",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model(modelName, X_train, X_test, y_train, y_test ):    \n",
    "    if modelName == 'LinearRegression':\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "        rf_eval = evaluate_model(model, X_test, y_test)\n",
    "        print('RMSE:', rf_eval['rmse'])   \n",
    "        print('-----------------------------')\n",
    "        #check_bias_variance (model, X_train, y_train, X_test, y_test, nRounds)\n",
    "    if modelName == 'DecisionTreeRegressor':\n",
    "        model = DecisionTreeRegressor(random_state = r_state)\n",
    "        model.fit(X_train, y_train)\n",
    "        rf_eval = evaluate_model(model, X_test, y_test)\n",
    "        print('RMSE:', rf_eval['rmse'])   \n",
    "        print('-----------------------------')\n",
    "        #check_bias_variance (model, X_train, y_train, X_test, y_test, nRounds)        \n",
    "    if modelName == 'SVN':\n",
    "        model = SVR()\n",
    "        model.fit(X_train, y_train)\n",
    "        rf_eval = evaluate_model(model, X_test, y_test)\n",
    "        print('RMSE:', rf_eval['rmse'])\n",
    "        print('-----------------------------')\n",
    "        #check_bias_variance (model, X_train, y_train, X_test, y_test, nRounds)        \n",
    "    if modelName == 'Lasso':\n",
    "        model = linear_model.Lasso()\n",
    "        model.fit(X_train, y_train)\n",
    "        rf_eval = evaluate_model(model, X_test, y_test)\n",
    "        print('RMSE:', rf_eval['rmse'])\n",
    "        print('-----------------------------')\n",
    "        #check_bias_variance (model, X_train, y_train, X_test, y_test, nRounds)        \n",
    "    if modelName == 'RandomForestRegressor':\n",
    "        model = RandomForestRegressor(random_state = r_state)\n",
    "        model.fit(X_train, y_train)\n",
    "        rf_eval = evaluate_model(model, X_test, y_test)\n",
    "        print('RMSE:', rf_eval['rmse'])\n",
    "        print('-----------------------------')        \n",
    "    if modelName == 'LinearSVR':\n",
    "        model = LinearSVR(random_state = r_state)\n",
    "        model.fit(X_train, y_train)\n",
    "        rf_eval = evaluate_model(model, X_test, y_test)\n",
    "        print('RMSE:', rf_eval['rmse'])\n",
    "    if modelName == 'SGDRegressor':\n",
    "        model = SGDRegressor(random_state=r_state)\n",
    "        model.fit(X_train, y_train)\n",
    "        rf_eval = evaluate_model(model, X_test, y_test)\n",
    "        print('RMSE:', rf_eval['rmse'])  \n",
    "    if modelName == 'AdaBoostRegressor':\n",
    "        model = AdaBoostRegressor(random_state=r_state)\n",
    "        model.fit(X_train, y_train)\n",
    "        rf_eval = evaluate_model(model, X_test, y_test)\n",
    "        print('RMSE:', rf_eval['rmse'])   \n",
    "        print('-----------------------------')\n",
    "        #check_bias_variance (model, X_train, y_train, X_test, y_test, nRounds)\n",
    "    if modelName == 'GradientBoostingRegressor':  \n",
    "        model = GradientBoostingRegressor(random_state=r_state)\n",
    "        model.fit(X_train, y_train)\n",
    "        rf_eval = evaluate_model(model, X_test, y_test)\n",
    "        print('RMSE:', rf_eval['rmse'])  \n",
    "        print('-----------------------------')\n",
    "        #check_bias_variance (model, X_train, y_train, X_test, y_test, nRounds)    \n",
    "    if modelName == 'XGBRegressor':\n",
    "        model = XGBRegressor()\n",
    "        model.fit(X_train, y_train)\n",
    "        rf_eval = evaluate_model(model, X_test, y_test)\n",
    "        print('RMSE:', rf_eval['rmse'])  \n",
    "        print('-----------------------------')\n",
    "        #check_bias_variance (model, X_train, y_train, X_test, y_test, nRounds)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95be468",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RMSE: 0.867561992499243\n",
    "#-----------------------------\n",
    "#Bias Variance analisys\n",
    "#Average expected loss: 0.758\n",
    "#Average bias: 0.732\n",
    "#Average variance: 0.026\n",
    "\n",
    "generate_model('AdaBoostRegressor', X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143aa61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_model('GradientBoostingRegressor', X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbdb3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_model('XGBRegressor', X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b82a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.06420771551222759\n",
    "generate_model('RandomForestRegressor', X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87001f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.0184404561903206\n",
    "generate_model('SVN', X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36aad18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.5532288510210452\n",
    "#generate_model('LinearSVR', X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd10845",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9.492037586612488e+16\n",
    "#generate_model('SGDRegressor', X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf46f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.7790143048388207\n",
    "#generate_model('LinearRegression', X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462d58f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.08443915887063108\n",
    "#generate_model('DecisionTreeRegressor', X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e572a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.007929730508921\n",
    "#generate_model('Lasso', X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cccc10c",
   "metadata": {},
   "source": [
    "# Tuning de hyperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dcaaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09610f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best: -0.599796 using {'max_features': 'sqrt', 'n_estimators': 1000}\n",
    "\n",
    "parameters = {'learning_rate': (0.05, 0.1, 0.20), 'n_estimators': (10,100)}\n",
    "\n",
    "#model = RandomForestRegressor(random_state = r_state)\n",
    "model = XGBRegressor()\n",
    "\n",
    "cv = KFold(n_splits=10, shuffle = True, random_state=r_state)\n",
    "search = GridSearchCV(model, parameters,  scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
    "result = search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best: %f using %s\" % (result.best_score_, result.best_params_))\n",
    "print('----------------------------------------------------------------')\n",
    "\n",
    "means = result.cv_results_['mean_test_score']\n",
    "stds = result.cv_results_['std_test_score']\n",
    "params = result.cv_results_['params']\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e774f26",
   "metadata": {},
   "source": [
    "Ahora se crea un nuevo modelos con los hyperparametros encontrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9680e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelT = XGBRegressor(learning_rate = 0.2, n_estimators = 100)\n",
    "modelT.fit(X_train, y_train)\n",
    "rf_eval = evaluate_model(modelT, X_test, y_test)\n",
    "print('RMSE:', rf_eval['rmse']) \n",
    "#check_bias_variance (modelT, X_train, y_train, X_test, y_test, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebad6909",
   "metadata": {},
   "source": [
    "# Feature importance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dd75d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = modelT.feature_importances_\n",
    "indices = np.argsort(imp)\n",
    "feat = X.columns\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), imp[indices], color='g', align='center')\n",
    "plt.yticks(range(len(indices)), [feat[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abecab6f",
   "metadata": {},
   "source": [
    "## Notas\n",
    "\n",
    "High bias can cause an algorithm to miss the relevant relations between features and target outputs (underfitting).\n",
    "\n",
    "Then, the bias of the model can be reduced by increasing the complexity by (1) implementing a boosting ensemble method, or (2) adding more features or doing feature engineering.\n",
    "\n",
    "\n",
    "\n",
    "High variance suggests large changes to the estimate of the target function with changes to the training dataset (overfitting).\n",
    "\n",
    "The variance instead can be reduced by (1) implementing a bagging ensemble method, or (2) constraining or shrinking estimated coefficients by regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9789b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Model \n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e604a6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(modelT, '../../models/SiteEnergyIntensityPrediction.joblib', compress=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
