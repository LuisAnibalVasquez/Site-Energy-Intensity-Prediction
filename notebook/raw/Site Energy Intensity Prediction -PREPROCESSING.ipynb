{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f8ec4d8",
   "metadata": {},
   "source": [
    "# Proprocesammiento\n",
    "\n",
    "En esta notebook se hace lo siguiente:  \n",
    "1.- se calcula la Mean de los features que tiene valores nulos para luego ser imputados.  \n",
    "2.- Se elimina las variables categoricas.  \n",
    "3.- se cacula en Z-score para eliminar los Outliers.  \n",
    "4.- Se caclula en valor VIF para ser usado para eliminas las variables multicolineares.  \n",
    "5.- Se determinan y corrigen los feautures Skewed.  \n",
    "6.- Se estandarizan las columnas usando un StandardScaler.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35217b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from category_encoders import TargetEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b6bba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9567328",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TRAIN = pd.read_csv('../../data/raw/train_dataset.csv')\n",
    "df_TEST = pd.read_csv('../../data/raw/x_test.csv')\n",
    "\n",
    "z_test = pd.read_csv('../../data/raw/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358e4718",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TRAIN['origen'] = 'train'\n",
    "df_TEST['site_eui'] = np.nan\n",
    "df_TEST['origen'] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f47e047",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_TRAIN, df_TEST], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bc2d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefe28ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# se completan los valores nulos con la media\n",
    "df_all['year_built'].fillna(df_all['year_built'].mean(), inplace=True)\n",
    "df_all['energy_star_rating'].fillna(df_all['energy_star_rating'].mean(), inplace=True)\n",
    "df_all['direction_max_wind_speed'].fillna(df_all['direction_max_wind_speed'].mean(), inplace=True)\n",
    "df_all['direction_peak_wind_speed'].fillna(df_all['direction_peak_wind_speed'].mean(), inplace=True)\n",
    "df_all['max_wind_speed'].fillna(df_all['max_wind_speed'].mean(), inplace=True)\n",
    "df_all['days_with_fog'].fillna(df_all['days_with_fog'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cde7474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se cdifican las columnas categoricas\n",
    "\n",
    "#     building_class onehot encoder        \n",
    "OneHot_dumies = pd.get_dummies(df_all['building_class'], dummy_na=False)\n",
    "for d in OneHot_dumies:\n",
    "    df_all[f'building_class_{d}'] = OneHot_dumies[d]  \n",
    "    \n",
    "#     State_Factor\n",
    "df_all['label_State_Factor'] = LabelEncoder().fit_transform(df_all['State_Factor'])\n",
    "\n",
    "#     facility_type    \n",
    "encoder = TargetEncoder()\n",
    "df_all['target_facility_type'] = encoder.fit_transform(df_all['facility_type'], df_all['site_eui'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80b6b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dff6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_all[df_all['origen']=='train']\n",
    "test = df_all[df_all['origen']=='test']\n",
    "\n",
    "train = train.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)\n",
    "\n",
    "y_train = train['site_eui']\n",
    "y_test = z_test['site_eui']\n",
    "\n",
    "X_train = train.drop(columns=['site_eui','id','origen', 'building_class','State_Factor','facility_type'])\n",
    "X_test = test.drop(columns=['site_eui','id','origen', 'building_class','State_Factor','facility_type']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5452acdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b2f99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('../../data/preprocesada/X_train.csv')\n",
    "X_test.to_csv('../../data/preprocesada/X_test.csv')    \n",
    "y_train.to_csv('../../data/preprocesada/y_train.csv')\n",
    "y_test.to_csv('../../data/preprocesada/y_test.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
